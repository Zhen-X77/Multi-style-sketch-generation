{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPrjSIMBrktaZ2M7GJp/ZKL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SD62Dxov71Xk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755456759920,"user_tz":-60,"elapsed":24718,"user":{"displayName":"Xiang Zhen","userId":"12352921533960858198"}},"outputId":"12261321-8f61-4fb3-cec6-1e3b84390c6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!time cp -r /content/drive/MyDrive/Dissertation/Dataset/Multiple_style3.zip /content/\n","!unzip -q /content/Multiple_style3.zip -d /content/"],"metadata":{"id":"XaRD3HlU74Xg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755456807440,"user_tz":-60,"elapsed":3816,"user":{"displayName":"Xiang Zhen","userId":"12352921533960858198"}},"outputId":"a1286929-4ad5-4a1b-c8f0-b8b05f6ac94e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","real\t0m2.731s\n","user\t0m0.001s\n","sys\t0m0.097s\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4X8-BLE8puN","executionInfo":{"status":"ok","timestamp":1754073963401,"user_tz":-60,"elapsed":209,"user":{"displayName":"Xiang Zhen","userId":"12352921533960858198"}},"outputId":"0cb9b5b3-afd2-47ea-eb49-e8ecb1541dcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Aug  1 18:46:02 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0             55W /  400W |   38389MiB /  40960MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!pip install opencv-python\n","!pip install einops\n","!git clone https://github.com/lllyasviel/ControlNet-v1-1-nightly.git\n","!pip install --upgrade basicsr torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"4xhpfxP1_oqa","executionInfo":{"status":"ok","timestamp":1755457073748,"user_tz":-60,"elapsed":264541,"user":{"displayName":"Xiang Zhen","userId":"12352921533960858198"}},"outputId":"148e0c08-4f7f-48c3-ce32-d825861c293e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n","Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n","Cloning into 'ControlNet-v1-1-nightly'...\n","remote: Enumerating objects: 2416, done.\u001b[K\n","remote: Counting objects: 100% (465/465), done.\u001b[K\n","remote: Compressing objects: 100% (126/126), done.\u001b[K\n","remote: Total 2416 (delta 375), reused 339 (delta 339), pack-reused 1951 (from 1)\u001b[K\n","Receiving objects: 100% (2416/2416), 65.14 MiB | 53.02 MiB/s, done.\n","Resolving deltas: 100% (1014/1014), done.\n","Collecting basicsr\n","  Downloading basicsr-1.4.2.tar.gz (172 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Collecting torchvision\n","  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n","Collecting addict (from basicsr)\n","  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from basicsr) (1.0.0)\n","Collecting lmdb (from basicsr)\n","  Downloading lmdb-1.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.0.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from basicsr) (4.12.0.88)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from basicsr) (11.3.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from basicsr) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.32.3)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from basicsr) (0.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from basicsr) (1.16.1)\n","Collecting tb-nightly (from basicsr)\n","  Downloading tb_nightly-2.21.0a20250817-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.6.0+cu124)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from basicsr) (4.67.1)\n","Collecting yapf (from basicsr)\n","  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch>=1.7 (from basicsr)\n","  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (4.14.1)\n","Collecting sympy>=1.13.3 (from torch>=1.7->basicsr)\n","  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.7->basicsr)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.7->basicsr)\n","  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.7->basicsr)\n","  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.7->basicsr)\n","  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.7->basicsr)\n","  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.7->basicsr)\n","  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.7->basicsr)\n","  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.7->basicsr)\n","  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.7->basicsr)\n","  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.7->basicsr)\n","  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n","Collecting nvidia-nccl-cu12==2.27.3 (from torch>=1.7->basicsr)\n","  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n","Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.7->basicsr)\n","  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.7->basicsr)\n","  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.7->basicsr)\n","  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==3.4.0 (from torch>=1.7->basicsr)\n","  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch>=1.7->basicsr) (75.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (2025.8.3)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (2025.6.11)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (25.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (0.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (1.74.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (3.8.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (5.29.5)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (3.1.3)\n","Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->basicsr) (4.3.8)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.7->basicsr) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tb-nightly->basicsr) (3.0.2)\n","Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m132.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Downloading lmdb-1.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.6/299.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tb_nightly-2.21.0a20250817-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yapf-0.43.0-py3-none-any.whl (256 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m129.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: basicsr\n","  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214818 sha256=f843bb1351e25c5d907fe8a4b9beccce3d6ae6084935502e0f63efe37fb09b23\n","  Stored in directory: /root/.cache/pip/wheels/6d/a4/b3/9f888ba88efcae6dd4bbce69832363de9c4051142674f779fa\n","Successfully built basicsr\n","Installing collected packages: nvidia-cusparselt-cu12, lmdb, addict, yapf, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tb-nightly, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, basicsr\n","  Attempting uninstall: nvidia-cusparselt-cu12\n","    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n","    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n","      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.1\n","    Uninstalling sympy-1.13.1:\n","      Successfully uninstalled sympy-1.13.1\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\n","fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed addict-2.4.0 basicsr-1.4.2 lmdb-1.7.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 tb-nightly-2.21.0a20250817 torch-2.8.0 torchvision-0.23.0 triton-3.4.0 yapf-0.43.0\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append(\"/content/ControlNet-v1-1-nightly\")"],"metadata":{"id":"xWfR8Ubgg6zB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"u3whuRoU8Vgi"}},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from PIL import Image\n","import os\n","from transformers import CLIPTextModel, CLIPTokenizer\n","import torch\n","from einops import rearrange\n","from annotator.midas import MidasDetector\n","\n","class SketchDataset(Dataset):\n","    def __init__(self, root_dir, tokenizer, image_processor, size=512):\n","        self.Source_dir = os.path.join(root_dir, \"Source\")\n","        self.Sketch_dir = os.path.join(root_dir, \"Sketch\")\n","        self.Caption_dir = os.path.join(root_dir, \"Caption\")\n","\n","        self.filenames = sorted([\n","            fname.split('_')[0] for fname in os.listdir(self.Source_dir)\n","            if fname.endswith(('.jpg', '.png'))\n","        ])\n","\n","        self.tokenizer = tokenizer\n","        self.image_processor = image_processor\n","        self.size = size\n","        self.MidasDetector = MidasDetector()\n","        self.style2lambda = {\n","            \"pencil\": 0.9,\n","            \"architectural line drawing\": 0.5,\n","            \"anime lineart\":0.3\n","        }\n","\n","    def __len__(self):\n","        return len(self.filenames)\n","\n","    def __getitem__(self, idx):\n","        fname = self.filenames[idx]\n","\n","        # Load image file\n","        Source_image = Image.open(os.path.join(self.Source_dir, fname + \"_left.png\")).convert(\"RGB\").resize((self.size, self.size))\n","        Sketch_image = Image.open(os.path.join(self.Sketch_dir, fname + \"_right.png\")).convert(\"RGB\").resize((self.size, self.size))\n","\n","        # Derive Canny map\n","        Canny_image = np.array(Source_image)\n","        Canny_image = cv2.Canny(Canny_image, 100, 200)\n","        Canny_image = cv2.cvtColor(Canny_image, cv2.COLOR_GRAY2RGB)\n","        Canny_image = torch.from_numpy(Canny_image).float() / 255.0\n","        Canny_image = rearrange(Canny_image, \"h w c ->  c h w\")\n","\n","        # Derive Depth map\n","        Depth_image = np.array(Source_image)\n","        Depth_image = self.MidasDetector(Depth_image)\n","        if Depth_image.ndim == 2:\n","          Depth_image = np.expand_dims(Depth_image, axis=2)\n","          Depth_image = np.repeat(Depth_image, 3, axis=2)\n","\n","        Depth_image = torch.from_numpy(Depth_image).float() / 255.0\n","        Depth_image = rearrange(Depth_image, \"h w c ->  c h w\")\n","\n","\n","        # Open text\n","        with open(os.path.join(self.Caption_dir, fname + \".txt\"), 'r', encoding='utf-8') as f:\n","            prompt = f.read().strip()\n","\n","        # Derive style caption\n","        style = \"\"\n","        try:\n","          start = prompt.lower().index(\"a \") + 2\n","          end = prompt.lower().index(\" sketch\", start)\n","          style = prompt[start:end].strip()\n","        except ValueError:\n","          style = \"UnKnown\"\n","\n","        # Get the text token\n","        Caption = self.tokenizer(prompt, padding=\"max_length\", max_length=77, truncation=True, return_tensors=\"pt\")\n","\n","        return {\n","            \"Canny_image\": Canny_image,\n","            \"Depth_image\": Depth_image,\n","            \"Sketch_image\": self.image_processor(Sketch_image),\n","            \"Caption_ids\": Caption.input_ids.squeeze(0),\n","            \"attention_mask\": Caption.attention_mask.squeeze(0),\n","            \"Style_lambda\": self.style2lambda[style],\n","            \"Style_name\": style\n","        }"],"metadata":{"id":"N_eMNh3i75z7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Avg meter"],"metadata":{"id":"EdZxLLrv8Zp6"}},{"cell_type":"code","source":["class AverageMeter(object):\n","  def __init__(self):\n","    self.reset()\n","\n","  def reset(self):\n","    self.val = 0\n","    self.avg = 0\n","    self.sum = 0\n","    self.count = 0\n","\n","  def update(self, val, n=1):\n","    self.val = val\n","    self.sum += val * n\n","    self.count += n\n","    self.avg = self.sum / self.count"],"metadata":{"id":"mVHRytuN79bv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loss Function"],"metadata":{"id":"7ASi_pQk8dKc"}},{"cell_type":"code","source":["import torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Huber_loss\n","def huber_loss(input, target, delta=1.0, reduction='mean'):\n","    diff = input - target\n","    abs_diff = diff.abs()\n","    quad = torch.clamp(abs_diff, max=delta)\n","    lin = abs_diff - quad\n","    loss = 0.5 * quad**2 + delta * lin\n","    if reduction == 'mean':\n","        return loss.mean()\n","    elif reduction == 'sum':\n","        return loss.sum()\n","    return loss\n","\n","\n","class SketchLoss(nn.Module):\n","    def __init__(\n","        self,\n","        latent_weight=1.0,        # MSE loss weight\n","        latent_l1_weight=0.0,      # L1 loss weight\n","        huber_weight=0.0,         # Huber loss weight\n","        huber_delta=1.0,         # Huber loss threshold\n","    ):\n","        super().__init__()\n","        self.latent_weight   = latent_weight\n","        self.latent_l1_weight= latent_l1_weight\n","        self.huber_weight    = huber_weight\n","        self.huber_delta     = huber_delta\n","\n","\n","    def forward(\n","        self,\n","        noise_pred,\n","        noise,\n","    ):\n","        total = 0.0\n","\n","        # MSE Loss\n","        if self.latent_weight > 0:\n","            latent_mse = F.mse_loss(noise_pred, noise)\n","            total = total + self.latent_weight * latent_mse\n","        else:\n","            latent_mse = noise_pred.new_zeros(())\n","\n","        # MAE Loss\n","        if self.latent_l1_weight > 0:\n","            latent_l1 = F.l1_loss(noise_pred, noise)\n","            total = total + self.latent_l1_weight * latent_l1\n","        else:\n","            latent_l1 = noise_pred.new_zeros(())\n","\n","        # Huber Loss\n","        if self.huber_weight > 0:\n","            latent_huber = huber_loss(noise_pred, noise, delta=self.huber_delta)\n","            total = total + self.huber_weight * latent_huber\n","        else:\n","            latent_huber = noise_pred.new_zeros(())\n","\n","        return total\n"],"metadata":{"id":"MM8cF2vk7_O8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Set seed and Layer select"],"metadata":{"id":"sDY-_m_p8jwR"}},{"cell_type":"code","source":["import random, numpy as np, torch\n","\n","def set_seed(seed):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  torch.backends.cudnn.deterministic = True\n","  torch.backends.cudnn.benchmark = False\n","  return torch.Generator(device=\"cuda\").manual_seed(seed)\n","\n","# Select mid layer\n","def get_mid_block_linear_modules(unet_model):\n","    target_modules = []\n","    for name, module in unet_model.named_modules():\n","        if \"mid_block\" in name and isinstance(module, torch.nn.Linear):\n","            if any(kw in name for kw in [\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"]):\n","                target_modules.append(name)\n","    return target_modules\n","\n","# Select up-sampling layer\n","def get_up_blocks_linear_modules(unet_model):\n","    target_modules = []\n","    for name, module in unet_model.named_modules():\n","        if \"up_blocks\" in name and isinstance(module, torch.nn.Linear):\n","          if any(kw in name for kw in [\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"]):\n","            target_modules.append(name)\n","    return target_modules\n","\n","# Select down-sampling layer\n","def get_down_blocks_linear_modules(unet_model):\n","    target_modules = []\n","    for name, module in unet_model.named_modules():\n","        if \"down_blocks\" in name and isinstance(module, torch.nn.Linear):\n","          if any(kw in name for kw in [\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"]):\n","            target_modules.append(name)\n","    return target_modules"],"metadata":{"id":"0tZdVO_U8BTq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training pipline"],"metadata":{"id":"z2xJ-OKr8SwJ"}},{"cell_type":"code","source":["from pickle import decode_long\n","from io import SEEK_SET\n","import torch\n","from torch.utils.data import DataLoader\n","from diffusers import StableDiffusionControlNetPipeline, UNet2DConditionModel, AutoencoderKL, DDPMScheduler, ControlNetModel\n","from transformers import CLIPTextModel, CLIPTokenizer\n","from peft import get_peft_model, LoraConfig, TaskType\n","from torchvision import transforms\n","from tqdm.notebook import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","from PIL import Image\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","\n","# Configuration\n","model_id = \"runwayml/stable-diffusion-v1-5\"                   #Pretrained unet model id\n","controlmodel_id_1 = \"lllyasviel/control_v11p_sd15_canny\"             #Pretrained controlnet model id (for Canny map)\n","controlmodel_id_2 = \"lllyasviel/control_v11f1p_sd15_depth\"            #Pretrained controlnet model id (for depth map)\n","dataset_path = \"/Multiple_style3\"             #Dataset path\n","output_dir = \"/LoRA \"                   #Location to save the LoRA Matrix\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","batch_size = 1    # Batch size\n","lr = 5e-5      # Learning rate\n","max_steps = 5000   # Training step\n","cond_scale_1 = 0.5  # Canny map control intensity\n","cond_scale_2 = 1.0  # Depth map control intensity\n","seed = 5711\n","\n","# Load Pretrained Model\n","tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder=\"tokenizer\")\n","text_encoder = CLIPTextModel.from_pretrained(model_id, subfolder=\"text_encoder\").to(device)\n","vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\").to(device)\n","unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\").to(device)\n","controlnet1 = ControlNetModel.from_pretrained(controlmodel_id_1).to(device)\n","controlnet2 = ControlNetModel.from_pretrained(controlmodel_id_2).to(device)\n","\n","noise_scheduler = DDPMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n","set_seed(seed)\n","\n","\n","# LoRA Configuration\n","target_modules = get_mid_block_linear_modules(unet)+get_up_blocks_linear_modules(unet) #Inject layer select\n","\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=16,\n","    target_modules=[\"to_q\",\"to_k\",\"to_v\",\"to_out.0\"],# Modified target modules\n","    lora_dropout=0.1,\n","    bias=\"none\"\n",")\n","unet = get_peft_model(unet, lora_config)\n","\n","# Data pre-processing\n","image_processor = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5], [0.5])\n","])\n","\n","# Load data\n","dataset = SketchDataset(dataset_path, tokenizer, image_processor)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Optimizer\n","optimizer = torch.optim.AdamW(unet.parameters(), lr=lr)\n","\n","# Training loop\n","step = 0\n","unet.train()\n","controlnet1.eval()\n","controlnet2.eval()\n","text_encoder.eval()\n","vae.eval()\n","train_loss = AverageMeter()\n","writer = SummaryWriter(\"runs/sketch_lora\")\n","for epoch in range(50):    # training epoch\n","    for batch in tqdm(dataloader, desc=f\"Epoch{epoch+1}\",leave=False):\n","        if step >= max_steps:\n","            break\n","\n","        Cond_image1 = batch[\"Canny_image\"].to(device)\n","        Cond_image2 = batch[\"Depth_image\"].to(device)\n","        Target_image = batch[\"Sketch_image\"].to(device)\n","        Input_ids = batch[\"Caption_ids\"].to(device)\n","        style_lambda = batch[\"Style_lambda\"].to(device)\n","\n","        # Encode to latent space\n","        latents = vae.encode(Target_image).latent_dist.sample() * 0.18215\n","\n","        # Add noise\n","        noise = torch.randn_like(latents)\n","        timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (latents.shape[0],), device=device).long()\n","        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n","\n","        # Get text embedding\n","        text_emb = text_encoder(Input_ids)[0]\n","\n","        # Predict noise\n","        down_block_res_samples_1, mid_block_res_sample_1 = controlnet1(\n","            sample=noisy_latents,\n","            timestep=timesteps,\n","            encoder_hidden_states=text_emb,\n","            controlnet_cond=Cond_image1,\n","            return_dict=False\n","            )\n","        down_block_res_samples_2, mid_block_res_sample_2 = controlnet2(\n","            sample=noisy_latents,\n","            timestep=timesteps,\n","            encoder_hidden_states=text_emb,\n","            controlnet_cond=Cond_image2,\n","            return_dict=False\n","        )\n","\n","        down_block_res_samples = [\n","            x1 * cond_scale_1+x2 * cond_scale_2 for x1, x2 in zip(down_block_res_samples_1,down_block_res_samples_2)\n","            ]\n","\n","        mid_block_res_sample_1 = mid_block_res_sample_1 * cond_scale_1\n","        mid_block_res_sample_2 = mid_block_res_sample_2 * cond_scale_2\n","\n","        noise_pred = unet(\n","            sample=noisy_latents,\n","            timestep=timesteps,\n","            encoder_hidden_states=text_emb,\n","            down_block_additional_residuals=down_block_res_samples,\n","            mid_block_additional_residual=mid_block_res_sample_1+mid_block_res_sample_2,\n","            ).sample\n","\n","        # Loss Configuration\n","        loss_fn = SketchLoss(\n","            latent_weight=style_lambda,\n","            latent_l1_weight=1-style_lambda,\n","            huber_weight=1,\n","            )\n","        loss = loss_fn(\n","            noise_pred=noise_pred,\n","            noise=noise\n","            )\n","\n","        # Backpropagation\n","        loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        train_loss.update(loss.item())\n","\n","        if step % 75 == 0:\n","            print(f\"Step {step}, Loss: {loss.item():.4f}, Avg_Loss:{train_loss.avg}\")\n","            writer.add_scalar(\"Avg_Loss/train\", train_loss.avg, step)\n","            writer.add_scalar(\"Loss/train\", loss.item(), step)\n","            train_loss.reset()\n","\n","        step += 1\n","\n","# Save model\n","writer.close()\n","unet.save_pretrained(output_dir)\n","print(\" Model training completed，saved in:\", output_dir)"],"metadata":{"id":"yiCiYydT8FNY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inference pipline"],"metadata":{"id":"nTWwCkaF8QFI"}},{"cell_type":"code","source":["from io import SEEK_SET\n","import torch\n","from diffusers import StableDiffusionControlNetPipeline, UNet2DConditionModel, AutoencoderKL, DDPMScheduler, ControlNetModel\n","from transformers import CLIPTextModel, CLIPTokenizer\n","from peft import PeftModel,PeftConfig\n","from PIL import Image\n","from torchvision import transforms\n","from torchvision.utils import save_image\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","from einops import rearrange\n","from annotator.midas import MidasDetector\n","\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model_id = \"runwayml/stable-diffusion-v1-5\"                  # pretrained unet model id\n","controlmodel_id_1 = \"lllyasviel/control_v11p_sd15_canny\"            # pretrained controlnet1 id (for canny map)\n","controlmodel_id_2 = \"lllyasviel/control_v11f1p_sd15_depth\"           # pretrained controlnet2 id (for depth map)\n","lora_path = \"/LoRA\"            # LoRA path\n","source_image_path = \"/Soure_img.png\"    # Source Image path\n","result_path = \"/output.png\"      # Generation result saving path\n","prompt = \"a pencil sketch of a room\"  # Prompt\n","num_inference_steps = 200  # denoise step\n","cond_scale_1 = 0.5   # Canny map control intensity\n","cond_scale_2 = 1.0   # Depth map control intensity\n","seed = 1589\n","\n","# Load pretrained model\n","tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder=\"tokenizer\")\n","text_encoder = CLIPTextModel.from_pretrained(model_id, subfolder=\"text_encoder\").to(device)\n","vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\").to(device)\n","unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\").to(device)\n","controlnet1 = ControlNetModel.from_pretrained(controlmodel_id_1).to(device)\n","controlnet2 = ControlNetModel.from_pretrained(controlmodel_id_2).to(device)\n","noise_scheduler = DDPMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n","\n","# Inject trained LoRA Matrix\n","unet = PeftModel.from_pretrained(unet, lora_path).to(device)\n","\n","# Input Image and Prompt\n","token=tokenizer(prompt, padding=\"max_length\", max_length=77, truncation=True, return_tensors=\"pt\")\n","prompt_emb=text_encoder(token.input_ids.to(device))[0].to(device)\n","\n","source_image= Image.open(source_image_path).convert(\"RGB\").resize((512,512))\n","source_image = np.array(source_image)\n","\n","\n","# Derive Canny map\n","canny_image = cv2.Canny(source_image, 100, 200)\n","canny_image = cv2.cvtColor(canny_image, cv2.COLOR_GRAY2RGB)\n","canny_image = torch.from_numpy(canny_image).float() / 255.0\n","canny_image = rearrange(canny_image, 'h w c -> 1 c h w').to(device)\n","\n","# Derive Depth map\n","mida=MidasDetector()\n","depth_image = mida(source_image)\n","if depth_image.ndim == 2:\n","          depth_image = np.expand_dims(depth_image, axis=2)\n","          depth_image = np.repeat(depth_image, 3, axis=2)\n","depth_image = torch.from_numpy(depth_image).float() / 255.0\n","depth_image = rearrange(depth_image, \"h w c -> 1 c h w\").to(device)\n","\n","\n","# Inference\n","text_encoder.eval()\n","vae.eval()\n","unet.eval()\n","controlnet1.eval()\n","controlnet2.eval()\n","latents = torch.randn((1,4,64,64),device=device)\n","# gen = set_seed(seed)\n","# latents=torch.randn((1,4,64,64),generator=gen,device=device)\n","noise_scheduler.set_timesteps(num_inference_steps)\n","\n","\n","with torch.no_grad():\n","  for t in noise_scheduler.timesteps:\n","    down_block_res_samples_1, mid_block_res_sample_1 = controlnet1(\n","        sample=latents,\n","        timestep=t,\n","        encoder_hidden_states=prompt_emb,\n","        controlnet_cond=canny_image,\n","        return_dict=False\n","    )\n","\n","    down_block_res_samples_2, mid_block_res_sample_2 = controlnet2(\n","        sample=latents,\n","        timestep=t,\n","        encoder_hidden_states=prompt_emb,\n","        controlnet_cond=depth_image,\n","        return_dict=False\n","    )\n","\n","    down_block_res_samples = [\n","        x1 * cond_scale_1+x2 * cond_scale_2 for x1,x2 in zip(down_block_res_samples_1,down_block_res_samples_2)\n","        ]\n","    mid_block_res_sample_1 = mid_block_res_sample_1 * cond_scale_1\n","    mid_block_res_sample_2 = mid_block_res_sample_2 * cond_scale_2\n","    mid_block_res_sample = mid_block_res_sample_1+mid_block_res_sample_2\n","\n","    noise_inference_pred = unet(\n","        sample=latents,\n","        timestep=t,\n","        encoder_hidden_states=prompt_emb,\n","        down_block_additional_residuals= down_block_res_samples,\n","        mid_block_additional_residual= mid_block_res_sample,\n","    ).sample\n","\n","    latents = noise_scheduler.step(noise_inference_pred, t, latents).prev_sample # Corrected variable name\n","\n","  # Post processing\n","  image = vae.decode(latents/0.18215).sample\n","  r,g,b = image[:,0:1],image[:,1:2],image[:,2:3]\n","  gray = 0.2989*r + 0.5870*g + 0.1140*b\n","  enhance = gray + 0.3\n","  image_en = enhance.repeat(1,3,1,1)\n","  save_image((image_en+1)/2,result_path) # save enhanced image"],"metadata":{"id":"tlLuRTfX8IgV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755458254459,"user_tz":-60,"elapsed":27880,"user":{"displayName":"Xiang Zhen","userId":"12352921533960858198"}},"outputId":"ea811afa-c7bd-4c4a-8ac1-663d3e5d0e34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-347325873.py:57: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n","  Image.fromarray(depth_image, mode='L').save(\"/content/depth_preview.png\")\n"]}]},{"cell_type":"markdown","source":["# Loss Curve"],"metadata":{"id":"S-8mMkWH8I-z"}},{"cell_type":"code","source":["#Launch the TensorBoard visualization\n","%reload_ext tensorboard\n","#Reading logs\n","%tensorboard --logdir runs/"],"metadata":{"id":"wqVHxMk58OsT"},"execution_count":null,"outputs":[]}]}